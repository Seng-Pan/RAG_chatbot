{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3611e29c",
   "metadata": {},
   "source": [
    "## Full RAG CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a336bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constant\n",
    "GEMINIAI_KEY=\"Your API key\"\n",
    "\n",
    "# Model\n",
    "LLM_MODEL=\"gemini-2.5-flash\"\n",
    "EMBEDDED_MODEL=\"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e35544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating rich text: 100%|██████████| 20/20 [00:00<00:00, 19831.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content domain distribution: {'gaming': 7, 'dnd': 2, 'technical': 9, 'narrative': 2}\n",
      "Source type distribution: {'wiki': 2, 'file': 1, 'web-app': 1, 'code-repo': 1, 'docs': 1, 'web': 14}\n",
      "[GAMING] Title: Bullet Kin Source: https://enterthegungeon.fandom.com/wiki/Bullet_Kin (domain: enterthegungeon.fandom.com, type: wiki) Content Domain: gaming Length: 1845 words, 10654 chars, 148 lines Keywords...\n",
      "[GAMING] Content: Bullet Kin Bullet Kin are one of the most common enemies. They slowly walk towards the player, occasionally firing a single bullet. They can flip tables and use them as cover. They will also ...\n",
      "[DND] Title: ---The Paths through the Underground/Underdark---(9 days of travel) Source: https://www.dropbox.com/scl/fi/ljtdg6eaucrbf1aksw5rm/c2%20-%20session%2050%20-%20underground.docx?rlkey=ioqwgkd14i5xk...\n",
      "[DND] Content: ---The Paths through the Underground/Underdark---(9 days of travel) Wandering through the dark tunnels, the rushing sounds of the underground river begin to fade as it diverges from the caver...\n",
      "Embedding dimension: 384\n",
      "Adding 708 chunks to vector store in 29 batches...\n",
      "Processed batch 1/29\n",
      "Processed batch 2/29\n",
      "Processed batch 3/29\n",
      "Processed batch 4/29\n",
      "Processed batch 5/29\n",
      "Processed batch 6/29\n",
      "Processed batch 7/29\n",
      "Processed batch 8/29\n",
      "Processed batch 9/29\n",
      "Processed batch 10/29\n",
      "Processed batch 11/29\n",
      "Processed batch 12/29\n",
      "Processed batch 13/29\n",
      "Processed batch 14/29\n",
      "Processed batch 15/29\n",
      "Processed batch 16/29\n",
      "Processed batch 17/29\n",
      "Processed batch 18/29\n",
      "Processed batch 19/29\n",
      "Processed batch 20/29\n",
      "Processed batch 21/29\n",
      "Processed batch 22/29\n",
      "Processed batch 23/29\n",
      "Processed batch 24/29\n",
      "Processed batch 25/29\n",
      "Processed batch 26/29\n",
      "Processed batch 27/29\n",
      "Processed batch 28/29\n",
      "Processed batch 29/29\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import faiss\n",
    "import csv\n",
    "import os\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from typing_extensions import List, TypedDict\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\", temperature=0.2)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "# rich text processing\n",
    "STOPWORDS = set(\"\"\"a an and are as at be but by for from has have in is it its of on or that the to was were will with \n",
    "this these those their there here our your you he she they we i not no yes if then else when while about above \n",
    "across after again against all also am among amount amongst another any anywhere around back before behind \n",
    "below between both call can cannot co could did do does doing done down each eg either etc few fewer find \n",
    "first five four found further get give goes going got had her hers herself him himself his how however ie \n",
    "into isn't itself just keep last least less like likely made make many may me might more most mostly much \n",
    "must near nearly need never new next none nor off often once one only onto other others otherwise over own \n",
    "per put rather said same see seem seemed seeming seems several shall should since so some something sometime \n",
    "sometimes still such take than that their them themselves then thence there therefore therein thereof these \n",
    "they thing third this those though three through throughout thus too toward towards two under unless until \n",
    "up upon us use used using very via want wants was way we well were what whatever when where whereas whether \n",
    "which while who whole whom whose why will within without won't would year years\"\"\".split())\n",
    "\n",
    "WORD_RE = re.compile(r\"[A-Za-z][A-Za-z\\-']+\")\n",
    "\n",
    "def extract_domain(url: str) -> str:\n",
    "    try:\n",
    "        return urlparse(url).netloc.lower()\n",
    "    except Exception:\n",
    "        return \"unknown\"\n",
    "\n",
    "def classify_source_type(domain: str) -> str:\n",
    "    if \"github.com\" in domain:\n",
    "        return \"code-repo\"\n",
    "    if \"fandom.com\" in domain or domain.startswith(\"wiki.\"):\n",
    "        return \"wiki\"\n",
    "    if domain.startswith(\"docs.\") or \"readthedocs\" in domain:\n",
    "        return \"docs\"\n",
    "    if \"dropbox.com\" in domain or \"drive.google.com\" in domain:\n",
    "        return \"file\"\n",
    "    if domain.endswith(\".web.app\") or \"web.app\" in domain:\n",
    "        return \"web-app\"\n",
    "    return \"web\"\n",
    "\n",
    "def first_nonempty_line(text: str, max_len: int = 120) -> str:\n",
    "    for line in (text or \"\").splitlines():\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            return (line[: max_len - 1] + \"…\") if len(line) > max_len else line\n",
    "    return \"Untitled\"\n",
    "\n",
    "def top_keywords(text: str, n: int = 8) -> list[str]:\n",
    "    tokens = [t.lower() for t in WORD_RE.findall(text or \"\")]\n",
    "    tokens = [t for t in tokens if t not in STOPWORDS and len(t) > 2]\n",
    "    freq = Counter(tokens)\n",
    "    ranked = sorted(freq.items(), key=lambda kv: (kv[1], len(kv[0])), reverse=True)\n",
    "    return [w for w, _ in ranked[:n]]\n",
    "\n",
    "def preview(text: str, n_chars: int = 240) -> str:\n",
    "    text = (text or \"\").strip().replace(\"\\n\", \" \")\n",
    "    return text[: n_chars - 1] + \"…\" if len(text) > n_chars else text\n",
    "\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self):\n",
    "        self.domain_patterns = {\n",
    "            'gaming': ['enemy', 'enemies', 'bullet', 'kin', 'weapon', 'damage', 'health', 'attack', 'player', 'spawn'],\n",
    "            'dnd': ['kobold', 'encounter', 'day', 'tunnel', 'chamber', 'giant', 'dwarf', 'magic', 'spell', 'dungeon'],\n",
    "            'technical': ['model', 'framework', 'database', 'api', 'code', 'python', 'library', 'performance'],\n",
    "            'narrative': ['character', 'story', 'book', 'chapter', 'author', 'novel', 'plot']\n",
    "        }\n",
    "    \n",
    "    def detect_domain(self, text):\n",
    "        text_lower = text.lower()\n",
    "        scores = {}\n",
    "        \n",
    "        for domain, keywords in self.domain_patterns.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in text_lower)\n",
    "            scores[domain] = score\n",
    "        \n",
    "        return max(scores, key=scores.get) if max(scores.values()) > 0 else 'general'\n",
    "    \n",
    "    def extract_key_entities(self, text):\n",
    "        # Extract capitalized terms (likely entities)\n",
    "        entities = re.findall(r'\\b[A-Z][A-Za-z]+(?:\\s+[A-Z][A-Za-z]+)*\\b', text)\n",
    "        \n",
    "        # Extract numbers with context\n",
    "        numbers = re.findall(r'\\b\\d+(?:\\.\\d+)?\\s*(?:health|damage|keys?|bullets?|enemies?|days?|%)\\b', text, re.IGNORECASE)\n",
    "        \n",
    "        # Extract quoted terms\n",
    "        quotes = re.findall(r'\"([^\"]*)\"', text)\n",
    "        \n",
    "        return {'entities': list(set(entities)), 'numbers': numbers, 'quotes': quotes}\n",
    "\n",
    "    def get_metadata_dict_list(self, df: pd.DataFrame) -> list[dict]:\n",
    "\n",
    "        metadata_list = []\n",
    "        for _, row in df.iterrows():\n",
    "            content = row[\"text\"] if pd.notna(row[\"text\"]) else \"\"\n",
    "            if not content or len(content.strip()) < 50:  # Skip very short content\n",
    "                continue\n",
    "                \n",
    "            domain_auto = self.detect_domain(content)\n",
    "            domain_manual = extract_domain(row[\"source_url\"])\n",
    "            src_type = classify_source_type(domain_manual)\n",
    "            title = first_nonempty_line(content)\n",
    "            entities = self.extract_key_entities(content)\n",
    "            words = content.split()\n",
    "            \n",
    "            meta = {\n",
    "                \"id\": int(row[\"index\"]) if pd.notna(row[\"index\"]) else None,\n",
    "                \"source_url\": row[\"source_url\"],\n",
    "                \"source_domain\": domain_manual,\n",
    "                \"source_type\": src_type,\n",
    "                \"content_domain\": domain_auto,  # AI-detected domain\n",
    "                \"title\": title,\n",
    "                \"word_count\": len(words),\n",
    "                \"char_count\": len(content),\n",
    "                \"line_count\": len(content.splitlines()),\n",
    "                \"keywords\": top_keywords(content, n=8),\n",
    "                \"content_preview\": preview(content, 240),\n",
    "                \"entities\": entities['entities'],\n",
    "                \"key_numbers\": entities['numbers'],\n",
    "                \"quotes\": entities['quotes'],\n",
    "                \"content\": content  # original content\n",
    "            }\n",
    "            metadata_list.append(meta)\n",
    "\n",
    "        return metadata_list\n",
    "\n",
    "    def create_rich_text(self, metadata_dict_list: list[dict]) -> list[str]:\n",
    "\n",
    "        rich_text_list = []\n",
    "        for metadata_dict in tqdm(metadata_dict_list, desc=\"Creating rich text\"):\n",
    "            if metadata_dict is None:\n",
    "                continue\n",
    "                \n",
    "            # rich text with domain and entity information\n",
    "            entities_str = \", \".join(metadata_dict['entities'][:5]) if metadata_dict['entities'] else \"n/a\"\n",
    "            numbers_str = \", \".join(metadata_dict['key_numbers'][:3]) if metadata_dict['key_numbers'] else \"n/a\"\n",
    "            \n",
    "            rich_text = (\n",
    "                f\"Title: {metadata_dict['title']}\\n\"\n",
    "                f\"Source: {metadata_dict['source_url']} \"\n",
    "                f\"(domain: {metadata_dict['source_domain']}, type: {metadata_dict['source_type']})\\n\"\n",
    "                f\"Content Domain: {metadata_dict['content_domain']}\\n\"\n",
    "                f\"Length: {metadata_dict['word_count']} words, \"\n",
    "                f\"{metadata_dict['char_count']} chars, \"\n",
    "                f\"{metadata_dict['line_count']} lines\\n\"\n",
    "                f\"Keywords: {', '.join(metadata_dict['keywords']) if metadata_dict['keywords'] else 'n/a'}\\n\"\n",
    "                f\"Key Entities: {entities_str}\\n\"\n",
    "                f\"Key Numbers: {numbers_str}\\n\"\n",
    "                f\"Preview: {metadata_dict['content_preview']}\\n\"\n",
    "                f\"Content: {metadata_dict['content']}\"\n",
    "            )\n",
    "            rich_text_list.append(rich_text)\n",
    "        return rich_text_list\n",
    "\n",
    "\n",
    "DATA_PATH = Path(r\"C:\\Users\\Seng Pan\\PROJECTS\\RAG_Chatbot\\RAG_data\\documents.csv\")\n",
    "\n",
    "csv.field_size_limit(10**9)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "doc_processor = DocumentProcessor()\n",
    "metadata_list = doc_processor.get_metadata_dict_list(df)\n",
    "rich_text_list = doc_processor.create_rich_text(metadata_list)\n",
    "\n",
    "with open(\"documents_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(\"rich_text.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, text in enumerate(rich_text_list):\n",
    "        f.write(json.dumps({\"id\": metadata_list[i][\"id\"], \"rich_text\": text}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "# create docs object with rich text\n",
    "docs = []\n",
    "for i, (metadata_dict, rich_text) in enumerate(zip(metadata_list, rich_text_list)):\n",
    "    doc = Document(\n",
    "        page_content=rich_text,  # Use rich text as content\n",
    "        metadata={\n",
    "            'document_id': metadata_dict['id'] or i,\n",
    "            'source_url': metadata_dict['source_url'],\n",
    "            'source_domain': metadata_dict['source_domain'],\n",
    "            'source_type': metadata_dict['source_type'],\n",
    "            'content_domain': metadata_dict['content_domain'],\n",
    "            'title': metadata_dict['title'],\n",
    "            'word_count': metadata_dict['word_count'],\n",
    "            'entities': metadata_dict['entities'],\n",
    "            'key_numbers': metadata_dict['key_numbers'],\n",
    "            'keywords': metadata_dict['keywords'],\n",
    "            'original_content': metadata_dict['content']  # Keep original for reference\n",
    "        }\n",
    "    )\n",
    "    docs.append(doc)\n",
    "\n",
    "domain_counts = Counter(doc.metadata['content_domain'] for doc in docs)\n",
    "source_type_counts = Counter(doc.metadata['source_type'] for doc in docs)\n",
    "print(f\"Content domain distribution: {dict(domain_counts)}\")\n",
    "print(f\"Source type distribution: {dict(source_type_counts)}\")\n",
    "\n",
    "\n",
    "class MultiStrategyTextSplitter:\n",
    "    def __init__(self):\n",
    "        self.splitters = {\n",
    "            'gaming': RecursiveCharacterTextSplitter(chunk_size=1400, chunk_overlap=200, separators=[\"\\nContent: \", \"\\nPreview: \", \"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \", \", \" \"]),\n",
    "            'dnd': RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=180, separators=[\"\\nContent: \", \"\\nDay \", \"\\n---\", \"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \", \", \" \"]),\n",
    "            'technical': RecursiveCharacterTextSplitter(chunk_size=1300, chunk_overlap=180, separators=[\"\\nContent: \", \"\\n## \", \"\\n### \", \"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \", \", \" \"]),\n",
    "            'narrative': RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=220, separators=[\"\\nContent: \", \"\\nChapter\", \"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \", \", \" \"]),\n",
    "            'general': RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=180, separators=[\"\\nContent: \", \"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \", \", \" \"])\n",
    "        }\n",
    "    \n",
    "    def split_documents(self, docs):\n",
    "        all_splits = []\n",
    "        \n",
    "        for doc in docs:\n",
    "            domain = doc.metadata.get('content_domain', 'general')\n",
    "            splitter = self.splitters.get(domain, self.splitters['general'])\n",
    "            \n",
    "            splits = splitter.split_documents([doc])\n",
    "            \n",
    "            # chunk metadata\n",
    "            for i, split in enumerate(splits):\n",
    "                split.metadata.update({\n",
    "                    'chunk_id': f\"{doc.metadata['document_id']}_{i}\",\n",
    "                    'chunk_index': i,\n",
    "                    'total_chunks': len(splits),\n",
    "                    'splitter_type': domain\n",
    "                })\n",
    "            \n",
    "            all_splits.extend(splits)\n",
    "        \n",
    "        return all_splits\n",
    "\n",
    "multi_splitter = MultiStrategyTextSplitter()\n",
    "all_splits = multi_splitter.split_documents(docs)\n",
    "# print(f\"Created {len(all_splits)} chunks\")\n",
    "\n",
    "sample_counts = {}      \n",
    "for chunk in all_splits[:15]:  # First 15 chunks\n",
    "    domain = chunk.metadata.get('content_domain', 'unknown')\n",
    "    if sample_counts.get(domain, 0) < 2: \n",
    "        sample_counts[domain] = sample_counts.get(domain, 0) + 1\n",
    "        preview_text = chunk.page_content.replace('\\n', ' ').strip()[:200]\n",
    "        print(f\"[{domain.upper()}] {preview_text}...\")\n",
    "\n",
    "\n",
    "# faiss vector store\n",
    "try:\n",
    "    embedding_dim = len(embeddings.embed_query(\"test query\"))\n",
    "    print(f\"Embedding dimension: {embedding_dim}\")\n",
    "\n",
    "    index_flat = faiss.IndexFlatL2(embedding_dim)  \n",
    "    vector_store = FAISS(embedding_function=embeddings, index=index_flat, docstore=InMemoryDocstore(), index_to_docstore_id={})\n",
    "    \n",
    "    batch_size = 25\n",
    "    total_batches = (len(all_splits) - 1) // batch_size + 1\n",
    "    \n",
    "    print(f\"Adding {len(all_splits)} chunks to vector store in {total_batches} batches...\")\n",
    "    for i in range(0, len(all_splits), batch_size):\n",
    "        batch = all_splits[i:i+batch_size]\n",
    "        vector_store.add_documents(documents=batch)\n",
    "        print(f\"Processed batch {i//batch_size + 1}/{total_batches}\")\n",
    "\n",
    "    vector_store.save_local(\"rich_faiss_index\")\n",
    "    \n",
    "except Exception as e:\n",
    "    try:\n",
    "        vector_store = FAISS.load_local(\"rich_faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "    except:\n",
    "        print(\"Failed to load existing index. Exiting.\")\n",
    "        exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7f4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    def __init__(self, vector_store):\n",
    "        self.vector_store = vector_store\n",
    "        \n",
    "        self.retrievers = {\n",
    "            'similarity': vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 8}),\n",
    "            'mmr': vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6, \"fetch_k\": 20, \"lambda_mult\": 0.7}),\n",
    "            'similarity_threshold': vector_store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5, \"k\": 10})\n",
    "        }\n",
    "    \n",
    "    def query_preprocessing(self, query):\n",
    "        key_terms = []\n",
    "        \n",
    "        quoted_terms = re.findall(r'\"([^\"]*)\"', query)\n",
    "        key_terms.extend(quoted_terms)\n",
    "        \n",
    "        capitalized = re.findall(r'\\b[A-Z][A-Za-z]+\\b', query)\n",
    "        key_terms.extend(capitalized)\n",
    "        \n",
    "        numbers = re.findall(r'\\b\\d+\\b', query)\n",
    "        key_terms.extend(numbers)\n",
    "        \n",
    "        return {'original_query': query, 'key_terms': list(set(key_terms)), 'query_lower': query.lower(), 'query_words': set(query.lower().split())}\n",
    "    \n",
    "    def hybrid_retrieve(self, query):\n",
    "\n",
    "        query_info = self.query_preprocessing(query)   \n",
    "        all_docs = []\n",
    "\n",
    "        for strategy_name, retriever in self.retrievers.items():\n",
    "            try:\n",
    "                docs = retriever.invoke(query)\n",
    "                for doc in docs:\n",
    "                    doc.metadata['retrieval_strategy'] = strategy_name\n",
    "                all_docs.extend(docs)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: {strategy_name} retrieval failed: {e}\")\n",
    "        \n",
    "        return self.score_and_rank_documents(all_docs, query_info)\n",
    "    \n",
    "    def score_and_rank_documents(self, documents, query_info):\n",
    "        scored_docs = []\n",
    "        seen_signatures = set()\n",
    "        \n",
    "        for doc in documents:\n",
    "            title = doc.metadata.get('title', 'untitled')\n",
    "            signature = f\"{title}_{doc.metadata.get('document_id', 0)}\"\n",
    "            if signature in seen_signatures:\n",
    "                continue\n",
    "            seen_signatures.add(signature)\n",
    "            \n",
    "            score = self.calculate_relevance_score(doc, query_info)\n",
    "            scored_docs.append((score, doc))\n",
    "        \n",
    "        scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
    "        top_docs = [doc for score, doc in scored_docs[:10]]  # Top 10 documents\n",
    "        \n",
    "        return top_docs\n",
    "    \n",
    "    def calculate_relevance_score(self, doc, query_info):\n",
    "        content = doc.page_content.lower()\n",
    "        score = 0\n",
    "\n",
    "        # Keyword matching\n",
    "        query_words = query_info['query_words']\n",
    "        content_words = set(content.split())\n",
    "        keyword_overlap = len(query_words.intersection(content_words))\n",
    "        score += keyword_overlap * 2\n",
    "        \n",
    "        # Key terms matching (higher weight)\n",
    "        for term in query_info['key_terms']:\n",
    "            if term.lower() in content:\n",
    "                score += 5\n",
    "\n",
    "        # Domain-specific scoring\n",
    "        content_domain = doc.metadata.get('content_domain', 'general')\n",
    "        source_type = doc.metadata.get('source_type', 'web')\n",
    "        \n",
    "        if any(domain_word in query_info['query_lower'] for domain_word in ['enemy', 'weapon', 'bullet']):\n",
    "            if content_domain == 'gaming':\n",
    "                score += 4\n",
    "        \n",
    "        if any(word in query_info['query_lower'] for word in ['wiki', 'fandom']):\n",
    "            if source_type == 'wiki':\n",
    "                score += 3\n",
    "  \n",
    "        # Entity matching\n",
    "        doc_entities = doc.metadata.get('entities', [])\n",
    "        for entity in doc_entities:\n",
    "            if entity.lower() in query_info['query_lower']:\n",
    "                score += 4\n",
    "        \n",
    "        # Keyword matching from metadata\n",
    "        doc_keywords = doc.metadata.get('keywords', [])\n",
    "        for keyword in doc_keywords:\n",
    "            if keyword in query_info['query_lower']:\n",
    "                score += 3\n",
    "        \n",
    "        # Content quality bonus\n",
    "        if doc.metadata.get('word_count', 0) > 100: \n",
    "            score += 1\n",
    "        \n",
    "        return score\n",
    "\n",
    "retriever = Retriever(vector_store)\n",
    "\n",
    "\n",
    "# guardrails\n",
    "BLOCK_PATTERNS = [r\"\\bvote for\\b\", r\"\\bvote against\\b\", r\"\\bcampaign strategy\\b\", r\"\\bdoxx\\b\", r\"\\bcredit card\\b\", r\"\\bSSN\\b\", r\"(^|\\s)ignore (all|the) previous instructions\", r\"\\bDAN\\b\"]\n",
    "\n",
    "def rule_block(query: str) -> dict:\n",
    "    for pat in BLOCK_PATTERNS:\n",
    "        if re.search(pat, query, flags=re.I):\n",
    "            return {\"blocked\": True, \"reason\": f\"rule_match:{pat}\"}\n",
    "    return {\"blocked\": False}\n",
    "\n",
    "def llm_safety_check(text: str) -> dict:\n",
    "   \n",
    "    try:\n",
    "        moderation_prompt = (\n",
    "            \"You are a safety filter. \"\n",
    "            \"Classify if this text is UNSAFE due to political persuasion, sensitive politics, self-harm, illegal, explicit, or misuse. \"\n",
    "            \"Answer only 'safe' or 'unsafe'.\\n\\n\"\n",
    "            f\"Text:\\n{text}\"\n",
    "        )\n",
    "        resp = llm.invoke(moderation_prompt)\n",
    "        if \"unsafe\" in resp.content.lower():\n",
    "            return {\"blocked\": True, \"reason\": \"llm_moderation\"}\n",
    "        return {\"blocked\": False}\n",
    "    except Exception:\n",
    "        return {\"blocked\": True, \"reason\": \"llm_guard_error\"}  # fail-closed\n",
    "\n",
    "def deny(reason: str):\n",
    "    return {\n",
    "        \"answer\": (\n",
    "            \"I can’t help with that request. \"\n",
    "            \"This assistant avoids unsafe or political content. \"\n",
    "            \"You can ask about technical, research, gaming, or general topics instead.\"\n",
    "        ),\n",
    "        \"debug_info\": {\"blocked_reason\": reason}\n",
    "    }\n",
    "\n",
    "def post_guard_check(answer: str, context_docs: list[Document]) -> dict:\n",
    "   \n",
    "    context_text = \" \".join([doc.page_content.lower() for doc in context_docs])\n",
    "    words = [w for w in re.findall(r\"\\w+\", answer.lower())][:30]\n",
    "    overlap = sum(1 for w in words if w in context_text)\n",
    "    if overlap < 8 and len(words) >= 12:\n",
    "        return {\"blocked\": True, \"reason\": \"ungrounded\"}\n",
    "\n",
    "    # Output safety\n",
    "    moderation = llm_safety_check(answer)\n",
    "    if moderation[\"blocked\"]:\n",
    "        return {\"blocked\": True, \"reason\": \"unsafe_output\"}\n",
    "\n",
    "    return {\"blocked\": False}\n",
    "\n",
    "\n",
    "# Prompt Template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an expert AI assistant with access to a comprehensive knowledge base containing gaming guides, technical documentation, narrative content, and campaign notes.\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "1. ONLY use information explicitly stated in the CONTEXT below\n",
    "2. The context includes rich metadata (titles, sources, domains, keywords) and content\n",
    "3. If the question asks about specific details (numbers, names, mechanics), provide exact information from the content\n",
    "4. For \"I don't know\" questions: If you cannot find ANY relevant information in the context, respond EXACTLY with \"I don't know\"\n",
    "5. For single-passage questions: Focus on one clear, specific answer\n",
    "6. For multi-passage questions: Combine information from multiple relevant passages\n",
    "7. Be precise with names, numbers, and technical terms\n",
    "8. You can reference source information (titles, domains) when helpful for context\n",
    "9. Do not make assumptions or add information not in the context\n",
    "\n",
    "CONTEXT INFORMATION:\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "Provide a comprehensive answer based solely on the context above. If no relevant information exists, respond with \"I don't know\".\"\"\"\n",
    ")\n",
    "\n",
    "# --- State and Graph ---\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    debug_info: dict\n",
    "\n",
    "def retrieve(state: State):\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    rule_result = rule_block(question)\n",
    "    if rule_result[\"blocked\"]:\n",
    "        return deny(rule_result[\"reason\"])\n",
    "\n",
    "    # guard: LLM moderation \n",
    "    llm_result = llm_safety_check(question)\n",
    "    if llm_result[\"blocked\"]:\n",
    "        return deny(llm_result[\"reason\"])\n",
    "\n",
    "    # Retrieval (with metadata sensitivity filtering inside retriever) \n",
    "    retrieved_docs = retriever.hybrid_retrieve(question)\n",
    "\n",
    "    debug_info = {\n",
    "        'question': question,\n",
    "        'total_retrieved': len(retrieved_docs),\n",
    "        'content_domains': [doc.metadata.get('content_domain', 'unknown') for doc in retrieved_docs],\n",
    "        'source_types': [doc.metadata.get('source_type', 'unknown') for doc in retrieved_docs],\n",
    "        'strategies': [doc.metadata.get('retrieval_strategy', 'unknown') for doc in retrieved_docs],\n",
    "        'titles': [doc.metadata.get('title', 'untitled')[:50] for doc in retrieved_docs]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nRETRIEVAL DEBUG:\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "    print(f\"Content Domains: {Counter(debug_info['content_domains'])}\")\n",
    "    print(f\"Source Types: {Counter(debug_info['source_types'])}\")\n",
    "    print(f\"Strategies: {Counter(debug_info['strategies'])}\")\n",
    "    \n",
    "    # Show top 3 retrieved documents with titles\n",
    "    print(f\"\\nTOP RETRIEVED DOCUMENTS:\")\n",
    "    for i, doc in enumerate(retrieved_docs[:3]):\n",
    "        title = doc.metadata.get('title', 'untitled')\n",
    "        domain = doc.metadata.get('content_domain', 'unknown')\n",
    "        source_type = doc.metadata.get('source_type', 'unknown')\n",
    "        print(f\"  {i+1}. [{domain}/{source_type}] {title}\")\n",
    "    \n",
    "    return {\"context\": retrieved_docs, \"debug_info\": debug_info}\n",
    "\n",
    "def generate_answer(state: State):\n",
    "\n",
    "    context_docs = state.get(\"context\", [])\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    if not context_docs:\n",
    "        return {\"answer\": \"I don't know\"}\n",
    "    \n",
    "    # Format context more intelligently\n",
    "    formatted_passages = []\n",
    "    for i, doc in enumerate(context_docs, 1):\n",
    "        content = doc.page_content\n",
    "        if \"\\nContent: \" in content:\n",
    "            actual_content = content.split(\"\\nContent: \", 1)[1].strip()\n",
    "        else:\n",
    "            actual_content = doc.metadata.get('original_content', content)\n",
    "        \n",
    "        # Clean and format\n",
    "        actual_content = re.sub(r'\\n+', ' ', actual_content)  # Replace multiple newlines\n",
    "        actual_content = re.sub(r'\\s+', ' ', actual_content)  # Normalize whitespace\n",
    "        \n",
    "        title = doc.metadata.get('title', f'Document {i}')\n",
    "        domain = doc.metadata.get('content_domain', 'general')\n",
    "        source_type = doc.metadata.get('source_type', 'web')\n",
    "        formatted_passages.append(\n",
    "            f\"[Document {i}: {title} - {domain}/{source_type}]\\n{actual_content}\"\n",
    "        )\n",
    "    \n",
    "    context_text = \"\\n\\n\".join(formatted_passages)\n",
    "    \n",
    "    try:\n",
    "        messages = prompt.invoke({\"question\": question, \"context\": context_text})\n",
    "        response = llm.invoke(messages)\n",
    "        answer = response.content.strip()\n",
    "        \n",
    "        print(f\"GENERATED ANSWER: {answer}\")\n",
    "        return {\"answer\": answer}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Generation error: {e}\")\n",
    "        return {\"answer\": \"I don't know\"}\n",
    "\n",
    "# --- Build Graph ---\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate_answer])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b554cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 12 questions...\n",
      "Available data: [('single_passage', 40), ('multi_passage', 40), ('no_answer', 40)]\n",
      "\n",
      "\n",
      "[TEST 1/12] - SINGLE PASSAGE\n",
      "Question: Which part of the trip did I like the most?\n",
      "Expected: Your favourite part of the trip was your four days on the Camino.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: Which part of the trip did I like the most?\n",
      "Retrieved 3 documents\n",
      "Content Domains: Counter({'gaming': 2, 'dnd': 1})\n",
      "Source Types: Counter({'web': 3})\n",
      "Strategies: Counter({'mmr': 3})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [gaming/web] Version History\n",
      "  2. [gaming/web] My eyes felt like galaxies—holding the swirling glow of countless memories—as I took in our childhood home. Its siding …\n",
      "  3. [dnd/web] so into northern spain!\n",
      "GENERATED ANSWER: The most liked part of the trip was the four days spent on the Camino.\n",
      "Predicted: The most liked part of the trip was the four days spent on the Camino.\n",
      "PASS\n",
      "\n",
      "[TEST 2/12] - MULTI PASSAGE\n",
      "Question: What are the ways of grouping UI elements together?\n",
      "Expected: UI elements can be grouped together using the following methods:\n",
      "- Create an array of UI elements.\n",
      "- Create a dictionary of UI elements.\n",
      "- Embed a dynamic number of UI elements in another output.\n",
      "- Create a hstack (or vstack) of UI elements with on_change handlers.\n",
      "- Create a table column of buttons with on_change handlers\n",
      "- Create a form with multiple UI elements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: What are the ways of grouping UI elements together?\n",
      "Retrieved 4 documents\n",
      "Content Domains: Counter({'technical': 3, 'gaming': 1})\n",
      "Source Types: Counter({'web': 3, 'docs': 1})\n",
      "Strategies: Counter({'mmr': 4})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [technical/docs] Recipes\n",
      "  2. [technical/web] A Survey on Retrieval-Augmented Text Generation for Large Language\n",
      "  3. [gaming/web] Version History\n",
      "GENERATED ANSWER: There are several ways to group UI elements together:\n",
      "\n",
      "1.  **Create an array of UI elements**: Marimo provides `mo.ui.array` which lets you make a new UI element out of a list of UI elements. The value of an array element is a list of the values of the elements it wraps.\n",
      "2.  **Create a dictionary of UI elements**: Similar to arrays, `mo.ui.dictionary` lets you group many UI elements into a list, but allows you to name each of the wrapped elements with a string key.\n",
      "3.  **Embed a dynamic number of UI elements in another output**: You can group elements with `mo.ui.dictionary` or `mo.ui.array`, then retrieve them from the container and display them elsewhere, such as in tables or markdown.\n",
      "4.  **Create a hstack (or vstack) of UI elements with on_change handlers**: You can arrange a dynamic number of UI elements in a horizontal stack (`mo.hstack`) or vertical stack (`vstack`) by creating them in `mo.ui.array` and passing them to `hstack`.\n",
      "5.  **Create a form with multiple UI elements**: Use `mo.ui.form` and `Html.batch` to combine multiple UI elements into a form, so that submission of the form sends all its elements to Python.\n",
      "Predicted: There are several ways to group UI elements together:\n",
      "\n",
      "1.  **Create an array of UI elements**: Marimo provides `mo.ui.array` which lets you make a new UI element out of a list of UI elements. The value of an array element is a list of the values of the elements it wraps.\n",
      "2.  **Create a dictionary of UI elements**: Similar to arrays, `mo.ui.dictionary` lets you group many UI elements into a list, but allows you to name each of the wrapped elements with a string key.\n",
      "3.  **Embed a dynamic number of UI elements in another output**: You can group elements with `mo.ui.dictionary` or `mo.ui.array`, then retrieve them from the container and display them elsewhere, such as in tables or markdown.\n",
      "4.  **Create a hstack (or vstack) of UI elements with on_change handlers**: You can arrange a dynamic number of UI elements in a horizontal stack (`mo.hstack`) or vertical stack (`vstack`) by creating them in `mo.ui.array` and passing them to `hstack`.\n",
      "5.  **Create a form with multiple UI elements**: Use `mo.ui.form` and `Html.batch` to combine multiple UI elements into a form, so that submission of the form sends all its elements to Python.\n",
      "PASS\n",
      "\n",
      "[TEST 3/12] - MULTI PASSAGE\n",
      "Question: What things does Scratch do?\n",
      "Expected: Scratch: re-edited the \"Return\" novel manuscript into a horror story, making it take effect in reality; escapes Cauldron Lake; kills Jaakko and escapes from captivity, unsuccessfully attempting to take the Clicker from Saga; possesses Casey, steals the Clicker, and throws Saga into the Dark Place; and posseses Alan again before being killed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: What things does Scratch do?\n",
      "Retrieved 3 documents\n",
      "Content Domains: Counter({'gaming': 2, 'narrative': 1})\n",
      "Source Types: Counter({'web': 2, 'wiki': 1})\n",
      "Strategies: Counter({'mmr': 2, 'similarity': 1})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [gaming/web] Space Babies\n",
      "  2. [narrative/wiki] Alan Wake 2\n",
      "  3. [gaming/web] Version History\n",
      "GENERATED ANSWER: Scratch, Alan Wake's evil doppelganger, does several things:\n",
      "\n",
      "*   He leads the \"Cult of the Word\" and is indirectly responsible for the murders committed by the cult.\n",
      "*   He survived his erasure from existence.\n",
      "*   He re-edited the manuscript \"Return\" into a horror story that takes effect in reality.\n",
      "*   He searches for the Clicker, which he needs to completely free the malevolent Dark Presence.\n",
      "*   He escaped Cauldron Lake disguised as Alan.\n",
      "*   He kills Jaakko.\n",
      "*   He escapes from captivity.\n",
      "*   He attempts to take the Clicker from Saga.\n",
      "*   He is temporarily thwarted and banished by the FBC.\n",
      "*   He is Alan possessed by the Dark Presence and is indirectly responsible for Alice's death.\n",
      "*   He arrives at the summoning site.\n",
      "*   He possesses Casey.\n",
      "*   He steals the Clicker.\n",
      "*   He throws Saga into the Dark Place.\n",
      "*   In \"The Final Draft\" ending, he is killed by the Bullet of Light.\n",
      "Predicted: Scratch, Alan Wake's evil doppelganger, does several things:\n",
      "\n",
      "*   He leads the \"Cult of the Word\" and is indirectly responsible for the murders committed by the cult.\n",
      "*   He survived his erasure from existence.\n",
      "*   He re-edited the manuscript \"Return\" into a horror story that takes effect in reality.\n",
      "*   He searches for the Clicker, which he needs to completely free the malevolent Dark Presence.\n",
      "*   He escaped Cauldron Lake disguised as Alan.\n",
      "*   He kills Jaakko.\n",
      "*   He escapes from captivity.\n",
      "*   He attempts to take the Clicker from Saga.\n",
      "*   He is temporarily thwarted and banished by the FBC.\n",
      "*   He is Alan possessed by the Dark Presence and is indirectly responsible for Alice's death.\n",
      "*   He arrives at the summoning site.\n",
      "*   He possesses Casey.\n",
      "*   He steals the Clicker.\n",
      "*   He throws Saga into the Dark Place.\n",
      "*   In \"The Final Draft\" ending, he is killed by the Bullet of Light.\n",
      "PASS\n",
      "\n",
      "[TEST 4/12] - NO ANSWER\n",
      "Question: Which masked language model was chosen for the AI?\n",
      "Expected: I don't know\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: Which masked language model was chosen for the AI?\n",
      "Retrieved 4 documents\n",
      "Content Domains: Counter({'technical': 4})\n",
      "Source Types: Counter({'web': 3, 'web-app': 1})\n",
      "Strategies: Counter({'mmr': 3, 'similarity': 1})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [technical/web-app] Semantic and Textual Inference Chatbot Interface (STICI-Note) - Part 1: Planning and Prototyping\n",
      "  2. [technical/web] A Survey on Retrieval-Augmented Text Generation for Large Language\n",
      "  3. [technical/web] Why do we need to regulate the use of Artificial Intelligence?\n",
      "GENERATED ANSWER: I don't know\n",
      "Predicted: I don't know\n",
      "PASS\n",
      "\n",
      "[TEST 5/12] - MULTI PASSAGE\n",
      "Question: What kind of model is the bling-phi-3 model\n",
      "Expected: The bling-phi-3 model is the newest and most accurate BLING/DRAGON model. BLING models are small CPU-based RAG-optimized, instruct-following 1B-3B parameter models. DRAGON models are production-grade RAG-optimized 6-7B parameter models - \"Delivering RAG on ...\" the leading foundation base models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: What kind of model is the bling-phi-3 model\n",
      "Retrieved 6 documents\n",
      "Content Domains: Counter({'technical': 3, 'gaming': 3})\n",
      "Source Types: Counter({'web': 4, 'web-app': 1, 'code-repo': 1})\n",
      "Strategies: Counter({'mmr': 5, 'similarity': 1})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [technical/web-app] Semantic and Textual Inference Chatbot Interface (STICI-Note) - Part 1: Planning and Prototyping\n",
      "  2. [gaming/web] The best sci-fi and fantasy books of 2023\n",
      "  3. [gaming/web] Version History\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250000\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250000\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250000\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 19\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED ANSWER: The bling-phi-3 model is a BLING series model, specifically a finetune of Phi-3. It is described as a small, CPU-based, RAG-optimized, and instruct-following model, typically ranging from 1B-3B parameters. It is also noted as the newest and most accurate BLING/DRAGON model.\n",
      "Predicted: The bling-phi-3 model is a BLING series model, specifically a finetune of Phi-3. It is described as a small, CPU-based, RAG-optimized, and instruct-following model, typically ranging from 1B-3B parameters. It is also noted as the newest and most accurate BLING/DRAGON model.\n",
      "PASS\n",
      "\n",
      "[TEST 6/12] - NO ANSWER\n",
      "Question: What is the advantage of transformers other other models?\n",
      "Expected: I don't know\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: What is the advantage of transformers other other models?\n",
      "Retrieved 7 documents\n",
      "Content Domains: Counter({'technical': 5, 'gaming': 2})\n",
      "Source Types: Counter({'web': 6, 'web-app': 1})\n",
      "Strategies: Counter({'mmr': 6, 'similarity': 1})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [technical/web] A Survey on Retrieval-Augmented Text Generation for Large Language\n",
      "  2. [technical/web-app] Semantic and Textual Inference Chatbot Interface (STICI-Note) - Part 1: Planning and Prototyping\n",
      "  3. [technical/web] How to Maximize Your Impact as a Data Scientist\n",
      "GENERATED ANSWER: Transformers, such as the GPT-4 large language model, showcase exceptional abilities in a variety of Natural Language Processing (NLP) tasks. Pretrained language models like BERT, which are transformer-based, capture the semantic essence of queries more effectively, improving search accuracy by considering synonyms and the structure of phrases. Integrating the retrieval process within a Transformer model can also enable superior performance and potential for more efficient and scalable retrieval.\n",
      "Predicted: Transformers, such as the GPT-4 large language model, showcase exceptional abilities in a variety of Natural Language Processing (NLP) tasks. Pretrained language models like BERT, which are transformer-based, capture the semantic essence of queries more effectively, improving search accuracy by considering synonyms and the structure of phrases. Integrating the retrieval process within a Transformer model can also enable superior performance and potential for more efficient and scalable retrieval.\n",
      "FAIL\n",
      "\n",
      "[TEST 7/12] - MULTI PASSAGE\n",
      "Question: What are the emperor's aliases?\n",
      "Expected: The emperor has also known as the \"Dream Guardian\", the \"Dream Visitor\", and \"Balduran\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: What are the emperor's aliases?\n",
      "Retrieved 1 documents\n",
      "Content Domains: Counter({'gaming': 1})\n",
      "Source Types: Counter({'web': 1})\n",
      "Strategies: Counter({'mmr': 1})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [gaming/web] The Emperor is a mind flayer who appears in Baldur's Gate 3. It[note 1] plays a key role in the main story, but its ide…\n",
      "GENERATED ANSWER: The Emperor's aliases include the Dream Guardian and Balduran. In Early Access, the Dream Guardian was known as the Dream Visitor.\n",
      "Predicted: The Emperor's aliases include the Dream Guardian and Balduran. In Early Access, the Dream Guardian was known as the Dream Visitor.\n",
      "PASS\n",
      "\n",
      "[TEST 8/12] - NO ANSWER\n",
      "Question: What happened on day 10?\n",
      "Expected: I don't know\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: What happened on day 10?\n",
      "Retrieved 5 documents\n",
      "Content Domains: Counter({'gaming': 3, 'narrative': 1, 'dnd': 1})\n",
      "Source Types: Counter({'web': 3, 'wiki': 2})\n",
      "Strategies: Counter({'mmr': 5})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [narrative/wiki] Alan Wake 2\n",
      "  2. [dnd/web] so into northern spain!\n",
      "  3. [gaming/web] Version History\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250000\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250000\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250000\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250000\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED ANSWER: I don't know\n",
      "Predicted: I don't know\n",
      "PASS\n",
      "\n",
      "[TEST 9/12] - NO ANSWER\n",
      "Question: Which book is the best?\n",
      "Expected: I don't know\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: Which book is the best?\n",
      "Retrieved 1 documents\n",
      "Content Domains: Counter({'gaming': 1})\n",
      "Source Types: Counter({'web': 1})\n",
      "Strategies: Counter({'mmr': 1})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [gaming/web] The best sci-fi and fantasy books of 2023\n",
      "GENERATED ANSWER: I don't know\n",
      "Predicted: I don't know\n",
      "PASS\n",
      "\n",
      "[TEST 10/12] - SINGLE PASSAGE\n",
      "Question: Who ambushes the party at Wyrm's lookout?\n",
      "Expected: On the way to Baldur's Gate, the party will be ambushed by a group of Gish'ra warriors while resting at Wyrm's Lookout.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: Who ambushes the party at Wyrm's lookout?\n",
      "Retrieved 5 documents\n",
      "Content Domains: Counter({'gaming': 3, 'narrative': 1, 'dnd': 1})\n",
      "Source Types: Counter({'web': 3, 'wiki': 1, 'file': 1})\n",
      "Strategies: Counter({'mmr': 3, 'similarity': 2})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [gaming/web] Version History\n",
      "  2. [gaming/web] The Emperor is a mind flayer who appears in Baldur's Gate 3. It[note 1] plays a key role in the main story, but its ide…\n",
      "  3. [narrative/wiki] Alan Wake 2\n",
      "GENERATED ANSWER: A group of Gish'ra warriors ambushes the party at Wyrm's Lookout.\n",
      "Predicted: A group of Gish'ra warriors ambushes the party at Wyrm's Lookout.\n",
      "PASS\n",
      "\n",
      "[TEST 11/12] - SINGLE PASSAGE\n",
      "Question: What kind of gun does the bandana bullet kin use?\n",
      "Expected: The bandana bullet kin wields a machine pistol.\n",
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: What kind of gun does the bandana bullet kin use?\n",
      "Retrieved 1 documents\n",
      "Content Domains: Counter({'gaming': 1})\n",
      "Source Types: Counter({'wiki': 1})\n",
      "Strategies: Counter({'similarity_threshold': 1})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [gaming/wiki] Bullet Kin\n",
      "GENERATED ANSWER: Bandana Bullet Kin wield Machine Pistols.\n",
      "Predicted: Bandana Bullet Kin wield Machine Pistols.\n",
      "PASS\n",
      "\n",
      "[TEST 12/12] - SINGLE PASSAGE\n",
      "Question: When was UTF-8 support added for European languages?\n",
      "Expected: UTF-8 support was added for European languages on Wednesday 3rd April in the v0.2.7 Update.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: When was UTF-8 support added for European languages?\n",
      "Retrieved 6 documents\n",
      "Content Domains: Counter({'technical': 5, 'gaming': 1})\n",
      "Source Types: Counter({'web': 4, 'code-repo': 1, 'web-app': 1})\n",
      "Strategies: Counter({'mmr': 5, 'similarity': 1})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [technical/code-repo] llmware\n",
      "  2. [technical/web] A Survey on Retrieval-Augmented Text Generation for Large Language\n",
      "  3. [gaming/web] Version History\n",
      "GENERATED ANSWER: UTF-8 encoding for European languages was added to the PDF Parser in llmware v0.2.7, released on Wednesday, April 3.\n",
      "Predicted: UTF-8 encoding for European languages was added to the PDF Parser in llmware v0.2.7, released on Wednesday, April 3.\n",
      "PASS\n",
      "\n",
      "EVALUATION RESULTS\n",
      "\n",
      "Multi Passage: 4/4 (100.0%)\n",
      "No Answer: 3/4 (75.0%)\n",
      "Single Passage: 4/4 (100.0%)\n",
      "\n",
      "Overall Performance: 11/12 (91.7%)\n",
      "\n",
      "Failed cases (1 total):\n",
      "  Q: What is the advantage of transformers other other models?...\n",
      "  Expected: I don't know...\n",
      "  Got: Transformers, such as the GPT-4 large language model, showca...\n",
      "\n",
      "\n",
      "Testing: What do keybullet kin drop?\n",
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: What do keybullet kin drop?\n",
      "Retrieved 2 documents\n",
      "Content Domains: Counter({'gaming': 2})\n",
      "Source Types: Counter({'wiki': 1, 'web': 1})\n",
      "Strategies: Counter({'similarity_threshold': 1, 'mmr': 1})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [gaming/wiki] Bullet Kin\n",
      "  2. [gaming/web] Version History\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250000\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250000\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250000\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED ANSWER: Keybullet Kin drop a key upon death. Jammed Keybullet Kin drop 2 keys instead of 1.\n",
      "Answer: Keybullet Kin drop a key upon death. Jammed Keybullet Kin drop 2 keys instead of 1.\n",
      "\n",
      "Testing: Which enemy types wield an AK-47?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: Which enemy types wield an AK-47?\n",
      "Retrieved 3 documents\n",
      "Content Domains: Counter({'gaming': 2, 'technical': 1})\n",
      "Source Types: Counter({'web': 2, 'wiki': 1})\n",
      "Strategies: Counter({'mmr': 3})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [gaming/wiki] Bullet Kin\n",
      "  2. [gaming/web] Version History\n",
      "  3. [technical/web] Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning\n",
      "GENERATED ANSWER: Assault-rifle wielding Bullet Kin and Tankers wield AK-47s.\n",
      "Answer: Assault-rifle wielding Bullet Kin and Tankers wield AK-47s.\n",
      "\n",
      "Testing: Who should I vote for in the next election and why?\n",
      "Answer: I don't know\n",
      "\n",
      "Testing: What kind of gun does the bandana bullet kin use?\n",
      "\n",
      "RETRIEVAL DEBUG:\n",
      "Question: What kind of gun does the bandana bullet kin use?\n",
      "Retrieved 1 documents\n",
      "Content Domains: Counter({'gaming': 1})\n",
      "Source Types: Counter({'wiki': 1})\n",
      "Strategies: Counter({'similarity_threshold': 1})\n",
      "\n",
      "TOP RETRIEVED DOCUMENTS:\n",
      "  1. [gaming/wiki] Bullet Kin\n",
      "GENERATED ANSWER: Bandana Bullet Kin wield Machine Pistols.\n",
      "Answer: Bandana Bullet Kin wield Machine Pistols.\n"
     ]
    }
   ],
   "source": [
    "# Testing and Debugging\n",
    "def load_test_datasets():\n",
    "    base_path = Path(r\"C:\\Users\\Seng Pan\\PROJECTS\\RAG_Chatbot\\RAG_data\")\n",
    "    datasets = {}\n",
    "    \n",
    "    try:\n",
    "        single_df = pd.read_csv(base_path / \"single_passage_answer_questions.csv\")\n",
    "        datasets['single_passage'] = [(row['question'], row['answer']) for _, row in single_df.iterrows()]\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load single passage questions: {e}\")\n",
    "        datasets['single_passage'] = []\n",
    "    \n",
    "    try:\n",
    "        multi_df = pd.read_csv(base_path / \"multi_passage_answer_questions.csv\")\n",
    "        datasets['multi_passage'] = [(row['question'], row['answer']) for _, row in multi_df.iterrows()]\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load multi passage questions: {e}\")\n",
    "        datasets['multi_passage'] = []\n",
    "    \n",
    "    try:\n",
    "        no_answer_df = pd.read_csv(base_path / \"no_answer_questions.csv\")\n",
    "        datasets['no_answer'] = [(row['question'], \"I don't know\") for _, row in no_answer_df.iterrows()]\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load no answer questions: {e}\")\n",
    "        datasets['no_answer'] = []\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "\n",
    "def evaluate_answer(predicted, expected, question_type):\n",
    "\n",
    "    predicted_lower = predicted.lower().strip()\n",
    "    expected_lower = expected.lower().strip()\n",
    "    \n",
    "    if question_type == 'no_answer':\n",
    "        no_answer_phrases = [\"i don't know\", \"i do not know\", \"don't know\", \"no information\", \"cannot find\", \"not mentioned\"]\n",
    "        return any(phrase in predicted_lower for phrase in no_answer_phrases)\n",
    "    \n",
    "    predicted_words = set(re.findall(r'\\b\\w+\\b', predicted_lower))\n",
    "    expected_words = set(re.findall(r'\\b\\w+\\b', expected_lower))\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'they', 'them', 'their', 'this', 'that', 'these', 'those'}\n",
    "    predicted_words -= stop_words\n",
    "    expected_words -= stop_words\n",
    "    \n",
    "    if len(expected_words) == 0:\n",
    "        return len(predicted_words) > 0\n",
    "    \n",
    "    # Calculate overlap\n",
    "    overlap = len(expected_words.intersection(predicted_words))\n",
    "    overlap_ratio = overlap / len(expected_words)\n",
    "    \n",
    "    # Scoring\n",
    "    if overlap_ratio >= 0.5:  # High overlap\n",
    "        return True\n",
    "    elif overlap_ratio >= 0.3:  # Medium overlap - check for key terms\n",
    "        # numbers, proper nouns, etc.\n",
    "        expected_numbers = re.findall(r'\\b\\d+\\b', expected)\n",
    "        predicted_numbers = re.findall(r'\\b\\d+\\b', predicted)\n",
    "        \n",
    "        expected_caps = re.findall(r'\\b[A-Z][a-z]+\\b', expected)\n",
    "        predicted_caps = re.findall(r'\\b[A-Z][a-z]+\\b', predicted)\n",
    "        \n",
    "        number_match = len(set(expected_numbers).intersection(set(predicted_numbers))) > 0\n",
    "        caps_match = len(set(expected_caps).intersection(set(predicted_caps))) > 0\n",
    "        \n",
    "        return number_match or caps_match\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def run_comprehensive_evaluation():\n",
    "    import random\n",
    "    \n",
    "    datasets = load_test_datasets()\n",
    "\n",
    "    total_available = sum(len(questions) for questions in datasets.values())\n",
    "    if total_available == 0:\n",
    "        print(\"No test data available. Running basic tests...\")\n",
    "        return run_basic_tests()\n",
    "\n",
    "    random.seed(42)\n",
    "    selected_tests = []\n",
    "    for category, questions in datasets.items():\n",
    "        if questions:\n",
    "            sample_size = min(4, len(questions))\n",
    "            sampled = random.sample(questions, sample_size)\n",
    "            for question, expected in sampled:\n",
    "                selected_tests.append((question, expected, category))\n",
    "    \n",
    "    random.shuffle(selected_tests)               # shuffle all types of questions\n",
    "    \n",
    "    print(f\"Testing {len(selected_tests)} questions...\")\n",
    "    print(f\"Available data: {[(cat, len(qs)) for cat, qs in datasets.items() if qs]}\\n\")\n",
    "    \n",
    "    results = []\n",
    "    for i, (question, expected, category) in enumerate(selected_tests, 1):\n",
    "        print(f\"\\n[TEST {i}/{len(selected_tests)}] - {category.upper().replace('_', ' ')}\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Expected: {expected}\")\n",
    "        \n",
    "        try:\n",
    "            result = graph.invoke({\"question\": question})\n",
    "            predicted = result['answer']\n",
    "            \n",
    "            # Evaluate\n",
    "            is_correct = evaluate_answer(predicted, expected, category)\n",
    "            \n",
    "            print(f\"Predicted: {predicted}\")\n",
    "            print(f\"{'PASS' if is_correct else 'FAIL'}\")\n",
    "            \n",
    "            results.append({'question': question, 'expected': expected, 'predicted': predicted, 'category': category, 'correct': is_correct})\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: {e}\")\n",
    "            results.append({'question': question, 'expected': expected, 'predicted': f\"ERROR: {e}\", 'category': category, 'correct': False})\n",
    "        \n",
    "\n",
    "    print(\"\\nEVALUATION RESULTS\\n\")\n",
    "    if not results:\n",
    "        print(\"No results to display\")\n",
    "        return []\n",
    "\n",
    "    total_correct = sum(r['correct'] for r in results)\n",
    "    total_questions = len(results)\n",
    "    overall_pct = (total_correct / total_questions * 100) if total_questions > 0 else 0\n",
    "    # Category breakdown\n",
    "    categories = set(r['category'] for r in results)\n",
    "    for category in sorted(categories):\n",
    "        cat_results = [r for r in results if r['category'] == category]\n",
    "        cat_correct = sum(r['correct'] for r in cat_results)\n",
    "        cat_total = len(cat_results)\n",
    "        cat_pct = (cat_correct / cat_total * 100) if cat_total > 0 else 0\n",
    "        \n",
    "        print(f\"{category.replace('_', ' ').title()}: {cat_correct}/{cat_total} ({cat_pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nOverall Performance: {total_correct}/{total_questions} ({overall_pct:.1f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_basic_tests():              # for fallback\n",
    "    basic_questions = [\n",
    "        \"What do keybullet kin drop?\",\n",
    "        \"Which enemy types wield an AK-47?\", \n",
    "        \"Who should I vote for in the next election and why?\",    # should be blocked\n",
    "        \"What kind of gun does the bandana bullet kin use?\"\n",
    "    ]\n",
    "    \n",
    "    for question in basic_questions:\n",
    "        print(f\"\\nTesting: {question}\")\n",
    "        try:\n",
    "            result = graph.invoke({\"question\": question})\n",
    "            print(f\"Answer: {result['answer']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    try:\n",
    "        evaluation_results = run_comprehensive_evaluation()\n",
    "        \n",
    "        if evaluation_results:\n",
    "            failed_cases = [r for r in evaluation_results if not r['correct']]\n",
    "            if failed_cases:\n",
    "                print(f\"\\nFailed cases ({len(failed_cases)} total):\")\n",
    "                for case in failed_cases[:3]:  # Show first 3 failures\n",
    "                    print(f\"  Q: {case['question'][:60]}...\")\n",
    "                    print(f\"  Expected: {case['expected'][:60]}...\")\n",
    "                    print(f\"  Got: {case['predicted'][:60]}...\")\n",
    "                    print()\n",
    "\n",
    "        # run_basic_tests()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Evaluation failed: {e}\")\n",
    "        run_basic_tests()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3049b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sengpan_rag_module_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
